
<!DOCTYPE html
  PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head>
      <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
   <!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      --><title>runpriordependentTS</title><meta name="generator" content="MATLAB 8.5"><link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"><meta name="DC.date" content="2020-07-22"><meta name="DC.source" content="runpriordependentTS.m"><style type="text/css">
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,sub,sup,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}:focus{outine:0}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a { color:#005fce; text-decoration:none; }
a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; } 

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:140%; padding: 20px; }

pre, code { font-size:12px; }
tt { font-size: 1.2em; }
pre { margin:0px 0px 20px; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 20px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }





  </style></head><body><div class="content"><h2>Contents</h2><div><ul><li><a href="#1">runpriordependentTS.m</a></li><li><a href="#2">Inputs:</a></li><li><a href="#3">Outputs:</a></li></ul></div><h2>runpriordependentTS.m<a name="1"></a></h2><pre class="codeinput"><span class="comment">% Runs prior dependent TS algorithm and returns regret and fraction of</span>
<span class="comment">% pulls.</span>
<span class="comment">%</span>
<span class="comment">% This code runs the prior dependent TS algorithm adapted to be used in our</span>
<span class="comment">% setting. For more information, on this algorithm see Algorithm 4 of</span>
<span class="comment">%</span>
<span class="comment">% - https://pubsonline.informs.org/doi/abs/10.1287/moor.2014.0650.</span>
<span class="comment">%</span>
<span class="comment">% For using the algorithm in this paper, which is designed for linear</span>
<span class="comment">% we can concatenate all the arm parameters to get a theta,</span>
<span class="comment">% parameter (of interest) in R^{k*d}.</span>
<span class="comment">% The k actions at time period t, with context x_t are given by:</span>
<span class="comment">% A_t = {[X_t, 0, 0, ..., 0], [0, X_t, 0, 0, ..., 0], ... ,</span>
<span class="comment">% [0, 0, ..., X_t]}$. After having this mapping, the algorithm builds</span>
<span class="comment">% confidence sets around theta and picks the action (corresponds to the</span>
<span class="comment">% same arm) that maximizes the optimistic reward.</span>

<span class="comment">% Our implementation uses Sherman-Morisson formula for fast rank one update</span>
<span class="comment">% of arm parameters. As construction of confidence intervals requires</span>
<span class="comment">% the knowledge of noise parameters, if this parameter is not provided,</span>
<span class="comment">% we use observations to estimate such parameter.</span>

<span class="comment">% Based on our observations, it is possible that the covariance matrices</span>
<span class="comment">% become ill-conditioned sometimes (or close to that) and hence we use</span>
<span class="comment">% Cholesky factorization to fixate this issue.</span>
<span class="comment">%</span>
</pre><h2>Inputs:<a name="2"></a></h2><pre class="language-matlab">k: Number of <span class="string">arms.</span>
T: Time horizon.
d: Dimension of <span class="string">covariates.</span>
b: A k*d matrix <span class="string">of</span> <span class="string">arm</span> <span class="string">parameters.</span>
sigma_e: Standard deviation <span class="string">of</span> <span class="string">noise</span> <span class="string">(or subgaussianity parameter).</span>
sigma_x: Standard deviation <span class="string">of</span> <span class="string">covariates</span>
    (used only <span class="keyword">for</span> context generation <span class="string">for</span> <span class="string">Gaussian</span> <span class="string">contexts).</span>
    This <span class="string">parameter</span> <span class="string">is</span> <span class="string">unused</span> <span class="string">if</span> <span class="string">noise</span> <span class="string">and</span> <span class="string">contexts</span> <span class="string">are</span> <span class="string">provided.</span>
xmax: Maximum of <span class="string">l2-norm</span> <span class="string">of</span> <span class="string">covariates</span>
    (used only <span class="keyword">for</span> context generation). This parameter <span class="string">is</span> <span class="string">unused</span> <span class="string">if</span>
    noise <span class="string">and</span> <span class="string">contexts</span> <span class="string">are</span> <span class="string">provided.</span>
prior_scale: The scaling <span class="string">factor</span> <span class="string">for</span> <span class="string">the</span> <span class="string">prior</span> <span class="string">(for the original version</span>
    set <span class="string">this</span> <span class="string">equal</span> <span class="string">to</span> <span class="string">1).</span>
prior_mu: Prior mean <span class="string">vector</span> <span class="string">of</span> <span class="string">gaussians.</span>
prior_sig: Prior covariance <span class="string">matrix</span> <span class="string">of</span> <span class="string">gaussians.</span>
sigma_start: The noise <span class="string">parameter</span> <span class="string">(or subgaussanity parameter)</span> <span class="string">to</span> <span class="string">start</span>
with. If true <span class="string">sigma</span> <span class="string">is</span> <span class="string">provided</span>, this <span class="string">parameter</span> <span class="string">is</span> <span class="string">not</span> <span class="string">used.</span>
use_true_sigma_e: Whether to <span class="string">use</span> <span class="string">true</span> <span class="string">noise</span> <span class="string">parameter</span>, sigma_e, <span class="keyword">for</span>
    construction <span class="string">of</span> <span class="string">confidence</span> <span class="string">sets</span> <span class="string">or</span> <span class="string">not.</span>
to_estimate_sigma_e: Whether to <span class="string">estimate</span> <span class="string">sigma_e</span> <span class="string">using</span> <span class="string">observations.</span>
    This <span class="string">is</span> <span class="string">only</span> <span class="string">effective</span> <span class="string">if</span> <span class="string">the</span> <span class="string">true</span> <span class="string">noise</span> <span class="string">parameter</span> <span class="string">is</span> <span class="string">not</span> <span class="string">provided.</span>
verbose: Whether to <span class="string">print</span> <span class="string">outputs</span> <span class="string">or</span> <span class="string">not.</span>
varargin: Additional arguments. In particular, <span class="keyword">if</span> these are <span class="string">not</span>
    provided <span class="string">the</span> <span class="string">noise</span> <span class="string">and</span> <span class="string">contexts</span> <span class="string">will</span> <span class="string">be</span> <span class="string">generated</span> <span class="string">according</span> <span class="string">to</span>
    Gaussian <span class="string">and</span> <span class="string">truncated</span> <span class="string">Gaussian</span> <span class="string">distributions.</span>
    In <span class="string">case</span> <span class="string">they</span> <span class="string">are</span> <span class="string">provided</span>, there <span class="string">should</span> <span class="string">exactly</span> <span class="string">be</span> <span class="string">THREE</span> <span class="string">additional</span>
    arguments. The first <span class="string">one</span> <span class="string">is</span> <span class="string">contexts.</span> <span class="string">The</span> <span class="string">second</span> <span class="string">one</span> <span class="string">is</span> <span class="string">a</span> <span class="string">binary</span>
    input, called <span class="string">noise_input.</span> <span class="string">If</span> <span class="string">noise_input</span> <span class="string">=</span> <span class="string">1</span>, this <span class="string">means</span> <span class="string">the</span> <span class="string">last</span>
    argument <span class="string">will</span> <span class="string">be</span> <span class="string">noise</span> <span class="string">e=(Y-X*beta).</span> <span class="string">On</span> <span class="string">the</span> <span class="string">other</span> <span class="string">hand</span>, <span class="keyword">if</span>
    noise_input = 0, then <span class="string">the</span> <span class="string">last</span> <span class="string">argument</span> <span class="string">will</span> <span class="string">be</span> <span class="string">Y</span> <span class="string">or</span>
    rewards. Note that <span class="string">the</span> <span class="string">noise</span> <span class="string">should</span> <span class="string">be</span> <span class="string">T*1</span> <span class="string">while</span> <span class="string">rewards</span> <span class="string">should</span> <span class="string">be</span>
    T*k.
</pre><h2>Outputs:<a name="3"></a></h2><pre class="language-matlab">regret: Cumulative regret <span class="string">as</span> <span class="string">a</span> <span class="string">running</span> <span class="string">sum</span> <span class="string">over</span> <span class="string">regret</span> <span class="string">terms.</span>
fractions: Fractions of <span class="string">pulls</span> <span class="string">of</span> <span class="string">different</span> <span class="string">arms.</span>
</pre><pre class="codeinput"><span class="keyword">function</span> [regret, fractions] = runpriordependentTS(k, T, d, b, <span class="keyword">...</span>
    sigma_e, sigma_x, xmax, prior_mu, <span class="keyword">...</span>
    prior_sig , sigma_start, use_true_sigma_e, to_estimate_sigma_e, <span class="keyword">...</span>
    verbose, varargin)

warning(<span class="string">'off'</span>,<span class="string">'all'</span>);
sigma_e_hat = sigma_start;

<span class="keyword">if</span> nargin==13 <span class="comment">% Context and noise are NOT provided, so generate those.</span>
    <span class="comment">% Noise is Gaussian with std sigma_e.</span>
    e = randn(T,1)*sigma_e;
    noise_input = 1;

    <span class="comment">% Contexts follow truncated gaussian distributions with l-infinity norm</span>
    <span class="comment">% at most xmax.</span>
    X = max(-xmax, min(xmax, mvnrnd(zeros(d, 1), sigma_x, T)));
<span class="keyword">else</span>
    X = varargin{1};
    noise_input = varargin{2};
    <span class="keyword">if</span>(noise_input==1)
        e = varargin{3};
    <span class="keyword">else</span>
        rewards = varargin{3};
    <span class="keyword">end</span>
<span class="keyword">end</span>

reward_vector = zeros(T, k);   <span class="comment">% Vector of all (potential) rewards.</span>
pull_ind = zeros(T, k);  <span class="comment">% Binary indicator whether each is pulled.</span>

regret = zeros(1, T);

cov_matrices_inv = zeros(d, d, k); <span class="comment">% Covariance matrices of Gaussians.</span>
mean_vector = zeros(d, k);
cov_inv_times_mean = zeros(d, k);
<span class="comment">%Compute v</span>

<span class="keyword">for</span> i=1:k
    cov_matrices_inv(:, :, i) = inv(prior_sig);  <span class="comment">% Initialize with prior.</span>
    mean_vector(:, i) = prior_mu ;  <span class="comment">% Mean of Gaussians.</span>
    cov_inv_times_mean(:, i) = cov_matrices_inv(:, :, i) * <span class="keyword">...</span>
        mean_vector(:, i);
<span class="keyword">end</span>

sampled_vectors = zeros(d,k);  <span class="comment">% Samples drawn according to posterior.</span>
residuals = zeros(T,1);


<span class="keyword">for</span> t=1:T
    x = X(t,:)';
    <span class="comment">% First: draw samples.</span>
    <span class="keyword">for</span> i=1:k
        cov_matrices_inv(:,:,i) = (cov_matrices_inv(:, :, i) <span class="keyword">...</span>
            + cov_matrices_inv(:, :, i)') / 2;
        [U, V]=eig(cov_matrices_inv(:, :, i));
        h=min(diag(V));
        <span class="keyword">if</span>(min(h)&lt;0)
            <span class="keyword">if</span>(verbose == 0)
                fprintf(<span class="string">'PD-TS: Inv. cov mat is ill-conditioned. \n'</span>);
                <span class="comment">% Cap the eigenvalues to 1e-9.</span>
                V = diag(max(h, 1e-9));
                cov_matrices_inv(:, :, i) = U * V * inv(U);
            <span class="keyword">end</span>
        <span class="keyword">end</span>
        sampled_vectors(:, i) = mean_vector(:, i) + transpose(<span class="keyword">...</span>
            randn(1, d) * chol(inv(cov_matrices_inv(:, :, i))) <span class="keyword">...</span>
            );
    <span class="keyword">end</span>

    <span class="comment">% Second: find which arm to play.</span>
    [~, arm_pulled]=max(x' * sampled_vectors);
    pull_ind(t, arm_pulled) = 1;

    <span class="comment">%Third: compute reward and regret.</span>
    <span class="keyword">if</span>(noise_input==1)
        bx = b*x;
        ourreward = bx(arm_pulled);
        bestreward = max(bx);
    <span class="keyword">else</span>
        ourreward = rewards(t, arm_pulled);
        bestreward = max(rewards(t,:));
    <span class="keyword">end</span>

    <span class="keyword">if</span> (t==1)
        regret(t) = bestreward - ourreward;
    <span class="keyword">else</span>
        regret(t) = regret(t-1) + bestreward - ourreward;
    <span class="keyword">end</span>

    <span class="comment">%Fourth: update parameters.</span>
    <span class="keyword">if</span>(noise_input==1)
        reward_vector(t, arm_pulled) = ourreward + e(t);
    <span class="keyword">else</span>
        reward_vector(t, arm_pulled) = rewards(t, arm_pulled);
    <span class="keyword">end</span>

    <span class="keyword">if</span>(use_true_sigma_e==1)
        R=sigma_e;
    <span class="keyword">else</span>
        R=sigma_e_hat;
    <span class="keyword">end</span>


    sigma_post = inv(cov_matrices_inv(:, :, arm_pulled) + (1 / R^2) <span class="keyword">...</span>
        * (x * x'));
    mu_post = sigma_post*((reward_vector(t, arm_pulled) / R^2) * x + <span class="keyword">...</span>
        cov_matrices_inv(:, :, arm_pulled) * mean_vector(:, arm_pulled));
    cov_matrices_inv(:, :, arm_pulled) = inv(sigma_post);
    mean_vector(:,arm_pulled)= mu_post;


    <span class="comment">%Fifth: update estimate of sigma_e.</span>
    <span class="keyword">if</span>(to_estimate_sigma_e==1)
         residuals(t) = reward_vector(t, arm_pulled) <span class="keyword">...</span>
             - x' * mean_vector(:, arm_pulled);
         <span class="keyword">if</span> (t&gt;k*d+1)
            sigma_e_hat = sqrt(sum(residuals.^2)/(t-d));
         <span class="keyword">end</span>
    <span class="keyword">end</span>
    <span class="keyword">if</span>(verbose==1)
        <span class="keyword">if</span> (mod(t,500)==0)
            fprintf(<span class="string">'PD-TS: t=%d, est. sigma_e = %f, sigma_e = %f. \n'</span>, <span class="keyword">...</span>
                t, sigma_e_hat, sigma_e);
        <span class="keyword">end</span>
    <span class="keyword">end</span>
<span class="keyword">end</span>
fractions = mean(pull_ind);  <span class="comment">%fraction of times each arm is pulled.</span>
<span class="keyword">if</span>(verbose==1)
    fprintf(<span class="string">'PD-TS: Total parameter estimation error = %f. \n'</span>, <span class="keyword">...</span>
        norm(b - cov_inv_times_mean', <span class="string">'fro'</span>))
    fprintf(<span class="string">'PD-TS: Fraction of pulls = %f. \n'</span>, fractions)
    fprintf(<span class="string">'PD-TS: Total regret occured = %f. \n'</span>, regret(end))
<span class="keyword">end</span>
<span class="keyword">end</span>
</pre><pre class="codeoutput error">Error using runpriordependentTS (line 75)
Not enough input arguments.
</pre><p class="footer"><br><a href="http://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2015a</a><br></p></div><!--
##### SOURCE BEGIN #####
%% runpriordependentTS.m

% Runs prior dependent TS algorithm and returns regret and fraction of 
% pulls.
% 
% This code runs the prior dependent TS algorithm adapted to be used in our
% setting. For more information, on this algorithm see Algorithm 4 of
%
% - https://pubsonline.informs.org/doi/abs/10.1287/moor.2014.0650.
% 
% For using the algorithm in this paper, which is designed for linear
% we can concatenate all the arm parameters to get a theta, 
% parameter (of interest) in R^{k*d}. 
% The k actions at time period t, with context x_t are given by:
% A_t = {[X_t, 0, 0, ..., 0], [0, X_t, 0, 0, ..., 0], ... ,                
% [0, 0, ..., X_t]}$. After having this mapping, the algorithm builds
% confidence sets around theta and picks the action (corresponds to the
% same arm) that maximizes the optimistic reward. 

% Our implementation uses Sherman-Morisson formula for fast rank one update
% of arm parameters. As construction of confidence intervals requires 
% the knowledge of noise parameters, if this parameter is not provided, 
% we use observations to estimate such parameter.

% Based on our observations, it is possible that the covariance matrices
% become ill-conditioned sometimes (or close to that) and hence we use
% Cholesky factorization to fixate this issue.
%
%% Inputs:
%   k: Number of arms.
%   T: Time horizon.
%   d: Dimension of covariates.
%   b: A k*d matrix of arm parameters.
%   sigma_e: Standard deviation of noise (or subgaussianity parameter).
%   sigma_x: Standard deviation of covariates 
%       (used only for context generation for Gaussian contexts). 
%       This parameter is unused if noise and contexts are provided.
%   xmax: Maximum of l2-norm of covariates 
%       (used only for context generation). This parameter is unused if 
%       noise and contexts are provided.
%   prior_scale: The scaling factor for the prior (for the original version
%       set this equal to 1).
%   prior_mu: Prior mean vector of gaussians.
%   prior_sig: Prior covariance matrix of gaussians.
%   sigma_start: The noise parameter (or subgaussanity parameter) to start
%   with. If true sigma is provided, this parameter is not used.
%   use_true_sigma_e: Whether to use true noise parameter, sigma_e, for
%       construction of confidence sets or not.
%   to_estimate_sigma_e: Whether to estimate sigma_e using observations.
%       This is only effective if the true noise parameter is not provided.
%   verbose: Whether to print outputs or not.
%   varargin: Additional arguments. In particular, if these are not
%       provided the noise and contexts will be generated according to 
%       Gaussian and truncated Gaussian distributions. 
%       In case they are provided, there should exactly be THREE additional
%       arguments. The first one is contexts. The second one is a binary
%       input, called noise_input. If noise_input = 1, this means the last
%       argument will be noise e=(Y-X*beta). On the other hand, if
%       noise_input = 0, then the last argument will be Y or
%       rewards. Note that the noise should be T*1 while rewards should be
%       T*k.
%% Outputs:
%
%   regret: Cumulative regret as a running sum over regret terms.
%   fractions: Fractions of pulls of different arms.
%


function [regret, fractions] = runpriordependentTS(k, T, d, b, ...
    sigma_e, sigma_x, xmax, prior_mu, ...
    prior_sig , sigma_start, use_true_sigma_e, to_estimate_sigma_e, ...
    verbose, varargin)

warning('off','all');
sigma_e_hat = sigma_start;

if nargin==13 % Context and noise are NOT provided, so generate those.
    % Noise is Gaussian with std sigma_e.
    e = randn(T,1)*sigma_e;
    noise_input = 1;
    
    % Contexts follow truncated gaussian distributions with l-infinity norm
    % at most xmax.
    X = max(-xmax, min(xmax, mvnrnd(zeros(d, 1), sigma_x, T)));  
else
    X = varargin{1};
    noise_input = varargin{2};
    if(noise_input==1)
        e = varargin{3};
    else
        rewards = varargin{3};
    end
end

reward_vector = zeros(T, k);   % Vector of all (potential) rewards.
pull_ind = zeros(T, k);  % Binary indicator whether each is pulled.

regret = zeros(1, T);

cov_matrices_inv = zeros(d, d, k); % Covariance matrices of Gaussians.
mean_vector = zeros(d, k);
cov_inv_times_mean = zeros(d, k);
%Compute v

for i=1:k
    cov_matrices_inv(:, :, i) = inv(prior_sig);  % Initialize with prior.
    mean_vector(:, i) = prior_mu ;  % Mean of Gaussians.
    cov_inv_times_mean(:, i) = cov_matrices_inv(:, :, i) * ...
        mean_vector(:, i);
end

sampled_vectors = zeros(d,k);  % Samples drawn according to posterior.
residuals = zeros(T,1);


for t=1:T
    x = X(t,:)';
    % First: draw samples.
    for i=1:k
        cov_matrices_inv(:,:,i) = (cov_matrices_inv(:, :, i) ...
            + cov_matrices_inv(:, :, i)') / 2;
        [U, V]=eig(cov_matrices_inv(:, :, i));
        h=min(diag(V));
        if(min(h)<0)
            if(verbose == 0)
                fprintf('PD-TS: Inv. cov mat is ill-conditioned. \n');
                % Cap the eigenvalues to 1e-9.
                V = diag(max(h, 1e-9));
                cov_matrices_inv(:, :, i) = U * V * inv(U);
            end
        end
        sampled_vectors(:, i) = mean_vector(:, i) + transpose(...
            randn(1, d) * chol(inv(cov_matrices_inv(:, :, i))) ...
            );
    end
    
    % Second: find which arm to play.
    [~, arm_pulled]=max(x' * sampled_vectors);
    pull_ind(t, arm_pulled) = 1;
    
    %Third: compute reward and regret.
    if(noise_input==1)
        bx = b*x;
        ourreward = bx(arm_pulled);
        bestreward = max(bx);
    else
        ourreward = rewards(t, arm_pulled);
        bestreward = max(rewards(t,:));
    end
    
    if (t==1)
        regret(t) = bestreward - ourreward;
    else
        regret(t) = regret(t-1) + bestreward - ourreward;
    end
    
    %Fourth: update parameters.
    if(noise_input==1)
        reward_vector(t, arm_pulled) = ourreward + e(t);
    else
        reward_vector(t, arm_pulled) = rewards(t, arm_pulled);
    end

    if(use_true_sigma_e==1)
        R=sigma_e;
    else
        R=sigma_e_hat;
    end
   
    
    sigma_post = inv(cov_matrices_inv(:, :, arm_pulled) + (1 / R^2) ... 
        * (x * x'));
    mu_post = sigma_post*((reward_vector(t, arm_pulled) / R^2) * x + ...
        cov_matrices_inv(:, :, arm_pulled) * mean_vector(:, arm_pulled));
    cov_matrices_inv(:, :, arm_pulled) = inv(sigma_post);
    mean_vector(:,arm_pulled)= mu_post;

   
    %Fifth: update estimate of sigma_e.
    if(to_estimate_sigma_e==1)
         residuals(t) = reward_vector(t, arm_pulled) ... 
             - x' * mean_vector(:, arm_pulled);
         if (t>k*d+1)
            sigma_e_hat = sqrt(sum(residuals.^2)/(t-d));
         end
    end
    if(verbose==1)
        if (mod(t,500)==0) 
            fprintf('PD-TS: t=%d, est. sigma_e = %f, sigma_e = %f. \n', ...
                t, sigma_e_hat, sigma_e);
        end
    end
end
fractions = mean(pull_ind);  %fraction of times each arm is pulled.
if(verbose==1)
    fprintf('PD-TS: Total parameter estimation error = %f. \n', ...
        norm(b - cov_inv_times_mean', 'fro'))
    fprintf('PD-TS: Fraction of pulls = %f. \n', fractions)
    fprintf('PD-TS: Total regret occured = %f. \n', regret(end))
end
end



##### SOURCE END #####
--></body></html>